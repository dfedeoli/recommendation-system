---
title: "Rating Prediction with MovieLens 10M Dataset"
author: "Danilo Ferreira de Oliveira"
date: "04/12/2021"
output: 
  pdf_document:
    latex_engine: xelatex
    number_sections: true
    toc: true
    toc_depth: 3
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) #fig.pos = 'h' fig.align = 'center' fig.cap
knitr::opts_chunk$set(comment = '>>' )
```

# Introduction

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

[Introduction to Data Science](https://rafalab.github.io/dsbook)

For this project, you will be creating a movie recommendation system using the MovieLens dataset. The version of movielens included in the dslabs package (which was used for some of the exercises in PH125.8x: Data Science: Machine Learning) is just a small subset of a much larger dataset with millions of ratings. You can find the [entire latest MovieLens dataset](https://grouplens.org/datasets/movielens/latest/)  here. You will be creating your own recommendation system using all the tools we have shown you throughout the courses in this series. We will use the [10M version of the MovieLens dataset](https://grouplens.org/datasets/movielens/10m/) to make the computation a little easier.

Second, you will train a machine learning algorithm using the inputs in one subset to predict movie ratings in the validation set. 

You will download the MovieLens data and run code we will provide to generate your datasets.

Recommendation systems are more complicated machine learning challenges because each outcome has a different set of predictors. For example, different users rate a different number of movies and rate different movies.

To compare different models or to see how well weâ€™re doing compared to a baseline, we will use root mean squared error (RMSE) as our loss function. We can interpret RMSE similar to standard deviation.

# Analysis

## Getting the data

```{r install_packages, echo=FALSE, warning=FALSE,message=FALSE}
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(ggplot2)) install.packages("ggplot2", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
if(!require(rlist)) install.packages("rlist", repos = "http://cran.us.r-project.org")
if(!require(stringr)) install.packages("stringr", repos = "http://cran.us.r-project.org")
if(!require(recosystem)) install.packages("recosystem", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(kableExtra)) install.packages("kableExtra", repos = "http://cran.us.r-project.org")
if(!require(tibble)) install.packages("tibble", repos = "http://cran.us.r-project.org")
if(!require(gridExtra)) install.packages("gridExtra", repos = "http://cran.us.r-project.org")
if(!require(cowplot)) install.packages("cowplot", repos = "http://cran.us.r-project.org")
```

```{r libraries, warning=FALSE,message=FALSE}
library(caret)     
library(tidyverse) 
library(ggplot2)
library(lubridate)
library(stringr)
library(recosystem)
library(data.table)
library(kableExtra)
library(tibble)
```

```{r load_edx, echo=FALSE}
load('rda/edx.rda')
```

## Exploratory Data Analysis

### Exploring the variables

```{r head_of_edx}
edx %>% as_tibble() 
```

We should analyze the quantity of unique values for each column variable. 

```{r summary_n_distinct}
edx %>% summarize(n_userIds = n_distinct(userId), n_movieIds = n_distinct(movieId),
                  n_titles = n_distinct(title), n_genrecomb = n_distinct(genres)) %>% 
  kbl(booktabs = TRUE) %>% kable_styling(latex_options = c("striped", "hold_position"))
```

Note that there is one more distinct `movieId` than `title`. We need to investigate why.

```{r movies_with_multiple_Ids}
edx %>% group_by(title) %>% summarize(n_movieIds = n_distinct(movieId)) %>% 
  filter(n_movieIds > 1) %>% kbl(booktabs = TRUE) %>% 
  kable_styling(latex_options = c("striped","hold_position"))
```

So we found out that _War of the Worlds (2005)_ has two distinct `movieIds`. We then see how many reviews for each of them there are.

```{r movieIds_for_WW2005, echo=FALSE}
edx %>% filter(title=='War of the Worlds (2005)') %>% 
  group_by(movieId) %>% summarize(title=title[1], genres=genres[1], n=n()) %>%  # Count of reviews for each movieId
  kbl(booktabs = TRUE) %>% kable_styling(latex_options = c("striped","hold_position"))
```


### Visualizing the data

We can now visualize the data. Let's see how is configured the ratings distribution.

```{r ratings_distribution, echo=FALSE, fig.width=6, fig.height=3, fig.fullwidth=TRUE, fig.align='center'}
edx %>% mutate(stars=ifelse(rating %in% c(1:5),'full','half')) %>% 
  ggplot(aes(factor(rating),fill=stars)) + geom_bar() + scale_fill_hue(c=80) + 
  labs(x='rating')
```

So we see that full star ratings are more common than those with half stars, since 4, 3 and 5 are the most common ones.

```{r hist_count, echo=FALSE, fig.align='center', fig.height=3}
p1 <- edx %>% count(userId) %>% ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + scale_x_log10() + 
  labs(x='Reviews given by user') # Number of reviews from each user

p2 <- edx %>% count(movieId) %>% ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + scale_x_log10() +
  labs(x='Reviews received by movie',y='') # Number of reviews of each movie

gridExtra::grid.arrange(p1, p2, ncol = 2)
rm(p1,p2)
```



```{r hist_avg_rating, echo=FALSE, fig.align='center', fig.height=3}
p1 <- edx %>% group_by(userId) %>% summarize(avg=mean(rating)) %>% 
  ggplot(aes(avg)) + geom_histogram(bins=35, color='black') +
  labs(x='Average rating given by user') #average rating a user gives
edx %>% group_by(userId) %>% summarize(avg=mean(rating)) %>% 
  filter(avg< 1.5) %>% dim() %>% .[1] # Few users average giving ratings under 1.5

p2 <- edx %>% group_by(movieId) %>% summarize(avg=mean(rating)) %>% 
  ggplot(aes(avg)) + geom_histogram(bins=35, color='black') +
  labs(x='Average rating received by movie') # Average rating received by a movie
edx %>% group_by(movieId) %>% summarize(avg=mean(rating)) %>% 
  filter(avg< 1.5) %>% dim() %>% .[1] # Few movies average less than 1.5
edx %>% group_by(movieId) %>% summarize(avg=mean(rating)) %>% 
  filter(avg> 4.25) %>% dim() %>% .[1] # Few movies average higher than 4.25

cowplot::plot_grid(p1,p2,ncol=1, align='v')
rm(p1,p2)
```

Compute the number of ratings for each movie and then plot it against the year the movie came out using a boxplot for each year. Use the square root transformation on the y-axis (number of ratings) when creating your plot.

```{r release_date}
release_date <- edx$title %>% str_extract('\\([0-9]{4}\\)') %>%
  str_extract('[0-9]{4}') %>% as.integer()
summary(release_date)
```


```{r released_edx, echo=FALSE}
edx <- data.frame(edx,released=release_date)
edx[which(edx$released==1915),] %>% summarize(movieId=movieId[1], title=title[1], genres=genres[1], n=n()) %>% kbl(booktabs = TRUE, linesep = "") %>% kable_styling(latex_options = c("striped","hold_position"))
```

```{r released_count, echo=FALSE}
edx %>% group_by(movieId) %>%
  summarize(n = n(), released = as.character(first(released))) %>%
  ggplot(aes(released, n)) + geom_boxplot(color='red',fill='blue', alpha=0.2) +
  scale_y_log10(breaks=c(1,10,100,200,500,1000,10000)) + scale_x_discrete(breaks=seq(1915,2005,5)) + 
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) + labs(x='year released',y='count')
```

We see that, on average, movies that came out after 1993 get more ratings. We also see that with newer movies, starting in 1993, the number of ratings decreases with year: the more recent a movie is, the less time users have had to rate it.

```{r released_avg_rating, echo=FALSE}
edx %>% group_by(movieId) %>%
  summarize(n = n(), released = as.character(first(released)), avg_rating=mean(rating)) %>%
  ggplot(aes(released, avg_rating)) + geom_boxplot(color='orange', fill='blue', alpha=0.5) + scale_x_discrete(breaks=seq(1915,2005,5)) +
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) + labs(x='year released', y='average rating')
edx <- edx[,-ncol(edx),drop=FALSE]
rm(release_date)
```


The genres contained in the dataset actually represent the combination of a series of unique genres. We count all the different genre combinations that appear in our dataset, arrange them in descending order for the number of reviews each. The table below show, as an example, the top 7 most reviewed genre combinations.

```{r genre_combinations, echo=FALSE}
edx %>% group_by(genres) %>% summarize(count = n()) %>% arrange(desc(count)) %>% head(n=7) %>% 
  data.frame(pos=c(1:7), .) %>% kbl(booktabs = TRUE, linesep = "") %>% kable_styling(latex_options = c("striped","hold_position"))
```

Genre effect on the ratings

```{r genre_effect, fig.fullwidth=TRUE, fig.align='center', fig.height=4}
gcomb_20 <- c(1,seq(31,444,32),444) 
edx %>% group_by(genres) %>%
  summarize(n = n(), avg = mean(rating), se = sd(rating)/sqrt(n())) %>%     
  filter(n > 1000) %>% arrange(desc(avg)) %>%  .[gcomb_20,] %>%
  mutate(genres = reorder(genres, avg)) %>%
  ggplot(aes(x = genres, y = avg,
             ymin = avg - 2*se, ymax = avg + 2*se)) + geom_point() + 
  geom_errorbar() + theme(axis.text.x=element_text(angle = 30, hjust = 1)) + 
  labs(x='', y= 'average rating')
```

There are 20 different genres in this dataset, and they are the following:

```{r all_genres, echo=FALSE}
rm(gcomb_20)
genre_combinations <- unique(edx$genres)     # Unique genre combinations
all_genres <- character()                    # Empty character vector
for (i in genre_combinations) {
  movie_genres <- str_split(i,'\\|')[[1]]    # Splitting the genre combinations
  for (j in movie_genres) {
    all_genres <- rlist::list.append(all_genres, j) # Appending each genre
  }
}
all_genres <- unique(all_genres)             # Unique genres in the dataset
rm(genre_combinations,movie_genres,i,j)
matrix(all_genres, nrow = 5, ncol= 4) %>% kbl(booktabs = TRUE, linesep = "") %>% kable_styling(latex_options =c("striped","hold_position"))
```

```{r all_genres_count}
all_genres_count <- sapply(all_genres, function(g) {
  sum(str_detect(edx$genres, g))      
}) %>% data.frame(review_count=.) %>% 
  arrange(desc(.))

```

```{r all_genres_count_div, echo=FALSE}
all_genres_count_div <-data.frame(row.names(all_genres_count)[1:10], all_genres_count[1:10,],
                                  row.names(all_genres_count)[11:20], all_genres_count[11:20,]) # Dividing table in two for better placement in report
colnames(all_genres_count_div) <- c('Genre','Count','Genre','Count')
all_genres_count_div %>% kbl(booktabs = TRUE, linesep = "") %>% column_spec(1:4, width='8em') %>% kable_styling(latex_options =c("striped","hold_position")) %>% add_header_above(c("all_genres_count[1:10]" = 2, "all_genres_count[11:20]" = 2))
 
```

why is there one genre missing in the plot? Here's why

```{r no_genres_listed}
edx[which(edx$genres=='(no genres listed)'),] %>% 
  summarize(movieId=movieId[1], userId=userId[1], title=title[1], genres=genres[1],
            n = n(), avg = mean(rating), se = sd(rating)/sqrt(n()))
```


```{r all_genres_avg_rating, echo=FALSE, fig.align='center', fig.width=6, fig.length=3.5}
all_genres_avg <- matrix(nrow=20,ncol=2)
i <- 1
for (var in all_genres) {
  vals <- edx[which(str_detect(edx$genres,as.character(var))),] %>% 
    summarize(n = n(), avg = mean(rating), se = sd(rating)/sqrt(n()))
  all_genres_avg[i,1] <- vals$avg
  all_genres_avg[i,2] <- vals$se
  i <- i+1
}
data.frame(genres=all_genres, avg=all_genres_avg[,1], se=all_genres_avg[,2]) %>% .[1:19,] %>%
  mutate(genres = reorder(genres, avg)) %>%
  ggplot(aes(x = genres, y = avg, ymin = avg - 2*se, ymax = avg + 2*se)) +  # Plotting the values and errors
  geom_point() + geom_errorbar() + theme(axis.text.x=element_text(angle = 45, hjust = 1)) + 
  labs(x='', y= 'average rating')
rm(var,i,vals,all_genres_avg)
```


We will then observe the top genres reviewed in this dataset, and how many reviews each one of them have. We accounted for the genres that were reviewed over a million times, resulting in 8 distinct possibilities.

```{r top_genres_reviews, echo=FALSE, fig.width=6, fig.height=3, fig.fullwidth=TRUE, fig.align='center'}
top_genres <- all_genres_count %>% filter(.>=1e6) # Genres with over 1 million reviews

top_genres %>% ggplot(aes(x= row.names(.), y = review_count, fill=row.names(.))) +
  geom_bar(stat='identity') + scale_fill_hue(c=40) + theme(legend.position="none") + 
  labs(x='', y='reviews count')
```

Let's see the unique movies that are in the dataset, how many times they were reviewed, and the number of distinct movies for each of the 8 top genres that were determined previously.

```{r unique_movies, echo=FALSE, fig.height=4, fig.fullwidth=TRUE, fig.align='center'}
unique_movies <- edx %>% group_by(title) %>% 
  summarize(title=title[1], genres=genres[1], count=n()) %>% arrange(desc(count))
unique_movies[1:10,] %>% mutate(title = str_remove(title, ", The"),
                                title = str_remove(title, " - A New Hope \\(a.k.a. Star Wars\\)")) %>% 
  ggplot(aes(x=reorder(title, count), y=count)) + geom_bar(stat = "identity") + labs(x='title') + coord_flip()
```

We now plot how many unique movies where reviewed for each of the top 8 genres.

```{r movies_top_genre, echo=FALSE, fig.height=3, fig.fullwidth=TRUE, fig.align='center'}
movies_per_top_genre <- sapply(row.names(top_genres), function(g) {
  sum(str_detect(unique_movies$genres, g))
})
data.frame(movies_per_top_genre) %>% 
  ggplot(aes(x= row.names(.), y = movies_per_top_genre, fill=row.names(.))) +
  geom_bar(stat='identity') + scale_fill_hue(c=40) + theme(legend.position="none") +
  labs(x='', y='movies count')
rm(movies_per_top_genre,top_genres,unique_movies,all_genres_count)
```

Turning timestamp into date and time

```{r timestamp_to_date, echo=FALSE}
edx <- mutate(edx, date = as_datetime(timestamp))
edx %>% as_tibble(.rows = 6)
```

Time effect on the dataset

```{r time_effect, message=FALSE, fig.height=3, fig.width=5, fig.align='center'}
edx %>% mutate(date = round_date(date, unit = "week")) %>%
  group_by(date) %>%
  summarize(rating = mean(rating)) %>%
  ggplot(aes(date, rating)) +
  geom_point() +
  geom_smooth()
```


## Feature Engineering



```{r binary_genres}

for (var in all_genres) {
  edx <- edx %>% mutate(genre=ifelse(str_detect(genres,as.character(var)),1,0))
  colnames(edx)[ncol(edx)] <- as.character(var)
}
rm(var)
edx <- edx[,-(4:7),drop=FALSE]
edx[,4:23] %>% as_tibble(.rows=6)
```



## Creating training and test sets

```{r partitioning, warning=FALSE}
set.seed(123, sample.kind = "Rounding")
index <- createDataPartition(edx$rating, times=1, p=0.2, list= FALSE)
test <- edx[index,]
train <- edx[-index,]
```

```{r cleaning_index_edx, echo=FALSE}
rm(index,edx)
```


```{r test_semi_join}
test <- test %>% 
  semi_join(train, by = "movieId") %>%
  semi_join(train, by = "userId")
```

 If N is the number of user-movie combinations, yu,i is the rating for movie i by user u, and y^u,i is our prediction, then RMSE is defined as follows:  RMSE function 

$$
RMSE = \sqrt{\frac{1}{N} \sum_{u,i}^{} \left( \hat{y}_{u,i} - y_{u,i} \right)^2 }
$$

```{r rmse_function, echo=FALSE}
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}
```

# Results

## Prediction models

### Naive RMSE

We start with a model that assumes the same rating for all movies and all users, with all the differences explained by random variation: If Î¼ represents the true rating for all movies and users and Ïµ represents independent errors sampled from the same distribution centered at zero, then:

$$
Y_{u,i} = \mu + \varepsilon_{u,i}
$$
In this case, the least squares estimate of Î¼ â€” the estimate that minimizes the root mean squared error â€” is the average rating of all movies across all users.

```{r naive_rmse}
mu <- mean(train$rating)
RMSE(test$rating, mu)
```

```{r naive_results, echo=FALSE}
rmse_results <- tibble(method = "Just the Average", RMSE = RMSE(test$rating, mu))
kbl(rmse_results, booktabs = TRUE) %>%  kable_styling(font_size = 8, latex_options = c("striped","hold_position"))
```

### Movie Effects

We can improve our model by adding a term, bi, that represents the average rating for movie i

$$
Y_{u,i} = \mu + b_i + \varepsilon_{u,i}
$$
bi  is the average of Yu,i minus the overall mean for each movie i.

Note that because there are thousands of b's, the lm() function will be very slow or cause R to crash, so we donâ€™t recommend using linear regression to calculate these effects.

```{r movie_effects}
movie_avgs <- train %>% group_by(movieId) %>% summarize(b_i = mean(rating-mu))

predicted_ratings <- mu + test %>% left_join(movie_avgs, by='movieId') %>%
  pull(b_i)

summary(predicted_ratings)
```



```{r movie_effects_results, echo=FALSE}
RMSE(test$rating, predicted_ratings)

rmse_results <- bind_rows(rmse_results,
                          tibble(method="Movie Effect Model",  
                                 RMSE = RMSE(test$rating, predicted_ratings)))
kbl(rmse_results, booktabs = TRUE) %>%  kable_styling(font_size = 8, latex_options = c("striped","hold_position"))
```



### Movie + User Effects

We can further improve our model by adding bu, the user-specific effect:

$$ 
Y_{u,i} = \mu + b_i + b_u + \varepsilon_{u,i}
$$

```{r m_u_effects}
user_avgs <- train %>%  left_join(movie_avgs, by='movieId') %>%
  group_by(userId) %>%  summarize(b_u = mean(rating - mu - b_i))

predicted_ratings <- test %>%
  left_join(movie_avgs, by='movieId') %>%  left_join(user_avgs, by='userId') %>%
  mutate(pred = mu + b_i + b_u) %>%  pull(pred)

summary(predicted_ratings)
```

`r sum(predicted_ratings<0.5)` e `r sum(predicted_ratings>5)`

```{r m_u_effects_results, echo=FALSE}
sum(predicted_ratings<0.5)
sum(predicted_ratings>5)
RMSE(test$rating, predicted_ratings)

rmse_results <- bind_rows(rmse_results,
                          tibble(method="Movie + User Effects Model",  
                                 RMSE = RMSE(test$rating, predicted_ratings)))
kbl(rmse_results, booktabs = TRUE) %>%  kable_styling(font_size = 8, latex_options = c("striped","hold_position"))

rm(predicted_ratings)
```


### Movie + User + Genre Effects

$$
Y_{u,i} = \mu + b_i + b_u + \sum_{k=1}^K x_{u,i} \beta_k + \varepsilon_{u,i}
$$

with $x^k_{u,i} = 1$ if $g_{u,i}$ is genre $k$

```{r beta_genre, echo=FALSE}
train <- train %>% left_join(movie_avgs, by='movieId') %>% 
  left_join(user_avgs, by='userId') 
test <- test %>% left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId')
rm(user_avgs,movie_avgs)

beta_k <- vector() # empty vector
for (i in seq_along(all_genres)) {
  b_value<- train %>% 
    group_by(!!sym(all_genres[[i]])) %>%          # Unquoting with !! and sym
    summarize(beta_k=mean(rating-mu-b_i-b_u)) %>% # beta value for all_genre[i]
    filter((.[1])==1) %>% .[[2]]                  # filter for all_genre[i]==1 and pulling the beta value
  beta_k <- append(beta_k, b_value)               # appending value to beta vector
}
rm(i,b_value)

df_beta<-data.frame(beta_k) 
rownames(df_beta) <- all_genres
# df_beta size (20,1)
df_beta_div <-data.frame(row.names(df_beta)[1:10], df_beta[1:10,],
                         row.names(df_beta)[11:20], df_beta[11:20,]) # Dividing table in two for better placement in report
colnames(df_beta_div) <- c('genre','beta_k','genre','beta_k')
df_beta_div %>% kbl(booktabs = TRUE, linesep = "") %>% column_spec(1:4, width='8em') %>% kable_styling(latex_options = c("striped","hold_position")) %>% add_header_above(c("df_beta [1:10]" = 2, "df_beta [11:20]" = 2))
```

beta equation

$$
\sum_{k=1}^K x_{u,i}\beta_{k} = x^{\{1\}}_{u,i}\beta_{1} +  x^{\{2\}}_{u,i}\beta_{2} + ... +  x^{\{20\}}_{u,i}\beta_{20}
$$

```{r m_u_g_effects, warning=FALSE}
sum_x_beta <- as.matrix(test[,4:23])%*%as.matrix(df_beta) 
sum_x_beta <- data.frame(sum_x_beta=sum_x_beta[,1])       

test <- data.frame(test, sum_x_beta)
rm(df_beta,beta_k,sum_x_beta,all_genres)

predicted_ratings <- test %>%
  mutate(pred = mu + b_i + b_u + sum_x_beta) %>%
  pull(pred)

summary(predicted_ratings)
```

```{r m_u_g_effects_results, echo=FALSE}
sum(predicted_ratings<0.5)
sum(predicted_ratings>5)
RMSE(test$rating, predicted_ratings)

rmse_results <- bind_rows(rmse_results,
                          tibble(method="Movie + User + Genre Effects Model",  
                                 RMSE = RMSE(test$rating, predicted_ratings)))
kbl(rmse_results, booktabs = TRUE) %>%  kable_styling(font_size = 8, latex_options = c("striped","hold_position"))
rm(predicted_ratings)
```

### Regularized Movie + User Effects

penalized least squares

$$
\sum_{u,i} \left(y_{u,i} - \mu - b_i - b_u \right)^2 + 
\lambda \left(\sum_{i} b_i^2 + \sum_{u} b_u^2\right)
$$

$$
\hat{b}_i(\lambda) = \frac{1}{\lambda + n_i} \sum_{u=1}^{n_i} \left(Y_{u,i} - \hat{\mu}\right)
$$
$$
\hat{b}_u(\lambda) = \frac{1}{\lambda + n_i} \sum_{u=1}^{n_i} \left(Y_{u,i} - \hat{b}_{i} - \hat{\mu}\right)
$$

```{r regularized_m_u_effects, fig.height=3, fig.width=5 , fig.align='center'}
train <- train %>% select(userId, movieId, rating)
test <- test %>% select(userId, movieId, rating)

lambdas <- seq(0, 10, 0.25)
rmses <- sapply(lambdas, function(l){
  b_i <- train %>%
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu)/(n()+l))       
  b_u <- train %>%
    left_join(b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mu)/(n()+l)) 
  predicted_ratings <-
    test %>%
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    mutate(pred = mu + b_i + b_u) %>%
    pull(pred)                                      
  return(RMSE(test$rating, predicted_ratings))
})
qplot(lambdas, rmses, xlab='lambda', ylab='RMSEs')
```

optimal lambda is `r lambdas[which.min(rmses)]` and its corresponding RMSE is `r min(rmses)`.

```{r lambda_rmse_results, echo=FALSE}
lambdas[which.min(rmses)] # Optimal lambda value
min(rmses)                # Minimum RMSE

rmse_results <- bind_rows(
  rmse_results,
  tibble(method="Regularized Movie + User Effects Model",  
         RMSE = min(rmses)))
kbl(rmse_results, booktabs = TRUE) %>%
  kable_styling(font_size = 8, latex_options = c("striped","hold_position"))

rm(lambdas,rmses,mu) # Cleaning variables to recover RAM space
```

### Matrix Factorization with _recosystem_ package

```{r recosystem_training, warning=FALSE, message=FALSE, results='hide'}
train_dm <- data_memory(user_index = train$userId, item_index = train$movieId,
                          rating = train$rating, index1 = TRUE) 
rm(train)

test_dm <- data_memory(user_index = test$userId, item_index = test$movieId, 
                       index1 = TRUE)                           
test_rating <- test$rating                                      
rm(test)

set.seed(123, sample.kind = "Rounding")
r <- Reco()                            
params = r$tune(train_dm, opts = list(dim = c(15, 20),
                                        costp_l1 = 0, #c(0, 0.1),
                                        costp_l2 = c(0.01, 0.1),
                                        costq_l1 = 0, #c(0, 0.1),
                                        costq_l2 = c(0.01, 0.1),
                                        lrate = c(0.075, 0.1), nthread = 2))

optimal_params = params$min

r$train(train_dm, opts = c(optimal_params, nthread = 1, niter = 20))
```

with the trained model, it is possible to predict the ratings for the test set.

```{r predicting_trainset, message=FALSE}
predicted_ratings = r$predict(test_dm, out_memory()) 

summary(predicted_ratings)
```

```{r MF_results, echo=FALSE}

sum(predicted_ratings<0.5)
sum(predicted_ratings>5)
RMSE(test_rating, predicted_ratings)

rmse_results <- bind_rows(rmse_results,
                          tibble(method="Matrix Factorization with SGD Model",  
                                 RMSE = RMSE(test_rating, predicted_ratings)))

kbl(rmse_results, booktabs = TRUE, linesep = "") %>%  
  kable_styling(font_size = 8, latex_options = c("striped","hold_position"))

rm(test_rating,predicted_ratings,params,test_dm)
```


## Training with full edx dataset

```{r load_edx_and_validation, echo=FALSE}
load('rda/edx.rda')
edx <- edx %>% select(userId, movieId, rating)
load('rda/validation.rda')
validation <- validation %>% select(userId, movieId, rating)
```


```{r recosystem_edx, message=FALSE, results='hide'}

train_dm <- data_memory(user_index = edx$userId, item_index = edx$movieId, 
                          rating = edx$rating, index1 = TRUE)
rm(edx)

r$train(train_dm, opts = c(optimal_params, nthread = 1, niter = 20))


```

predicting for validation dataset

```{r prediction_edx, message=FALSE}
validation_dm <- data_memory(user_index = validation$userId,
                             item_index = validation$movieId, index1 = TRUE)
validation_rating <- validation$rating

predicted_ratings = r$predict(validation_dm, out_memory()) 
rm(train_dm,validation)

summary(predicted_ratings)
```

```{r results_validation, echo=FALSE}
sum(predicted_ratings<0.5)
sum(predicted_ratings>5)
RMSE(validation_rating, predicted_ratings)

rmse_validation <- tibble(method="Matrix Factorization with SGD Model",  
                                 RMSE = RMSE(validation_rating, predicted_ratings))
kbl(rmse_validation, booktabs = TRUE) %>%  kable_styling(font_size = 8, latex_options = c("striped","hold_position"))
```


# Conclusion




